{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9822c7",
   "metadata": {},
   "source": [
    "# Improved Hidden Markov Model for Hangman\n",
    "\n",
    "## Improvements over Basic HMM:\n",
    "1. **N-gram Transition Probabilities** - Model letter sequences\n",
    "2. **Enhanced Pattern Matching** - Better handling of partial words\n",
    "3. **Adaptive Smoothing** - Handle unseen patterns gracefully\n",
    "4. **Context-Aware Predictions** - Use bigram/trigram context\n",
    "5. **Vowel/Consonant Balance** - Strategic letter selection\n",
    "\n",
    "**Goal:** Improve from 19.9% to 30%+ while keeping HMM framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8465c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c327238",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac37e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean data\n",
    "def load_and_clean_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        words = []\n",
    "        for line in f:\n",
    "            word = line.strip().lower()\n",
    "            word = ''.join(c for c in word if c.isalpha())\n",
    "            if len(word) >= 2:\n",
    "                words.append(word)\n",
    "    return words\n",
    "\n",
    "corpus = load_and_clean_data('Data/Data/corpus.txt')\n",
    "test_words = load_and_clean_data('Data/Data/test.txt')\n",
    "\n",
    "print(f\"Corpus: {len(corpus)} words ({len(set(corpus))} unique)\")\n",
    "print(f\"Test: {len(test_words)} words ({len(set(test_words))} unique)\")\n",
    "print(f\"Overlap: {len(set(corpus) & set(test_words))} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c8083",
   "metadata": {},
   "source": [
    "## 2. Improved HMM with N-gram Features\n",
    "\n",
    "### Key Improvements:\n",
    "- **Emission Probabilities:** Position-based letter frequencies (original HMM)\n",
    "- **Transition Probabilities:** Bigram/trigram patterns (NEW)\n",
    "- **Smoothing:** Laplace smoothing for unseen patterns (NEW)\n",
    "- **Context:** Use revealed letters for predictions (ENHANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c89f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedHMM:\n",
    "    \"\"\"Enhanced HMM with N-gram transition probabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing=0.1):\n",
    "        # Emission probabilities (position-based)\n",
    "        self.emission_prob = {}  # P(letter | position, word_length)\n",
    "        \n",
    "        # Transition probabilities (sequence-based)\n",
    "        self.bigram_prob = defaultdict(Counter)  # P(letter_i+1 | letter_i)\n",
    "        self.trigram_prob = defaultdict(lambda: defaultdict(Counter))  # P(letter_i+2 | letter_i, letter_i+1)\n",
    "        \n",
    "        # Overall frequencies\n",
    "        self.unigram_freq = Counter()\n",
    "        self.length_freq = {}\n",
    "        \n",
    "        self.smoothing = smoothing\n",
    "        self.vowels = set('aeiou')\n",
    "        \n",
    "    def train(self, words):\n",
    "        \"\"\"Train HMM on corpus\"\"\"\n",
    "        print(\"Training Improved HMM...\")\n",
    "        \n",
    "        for word in tqdm(words, desc=\"Training\"):\n",
    "            word_len = len(word)\n",
    "            \n",
    "            # Initialize emission probabilities\n",
    "            if word_len not in self.emission_prob:\n",
    "                self.emission_prob[word_len] = {}\n",
    "                self.length_freq[word_len] = Counter()\n",
    "            \n",
    "            # Emission probabilities: P(letter | position)\n",
    "            for pos, letter in enumerate(word):\n",
    "                if pos not in self.emission_prob[word_len]:\n",
    "                    self.emission_prob[word_len][pos] = Counter()\n",
    "                self.emission_prob[word_len][pos][letter] += 1\n",
    "                self.unigram_freq[letter] += 1\n",
    "                self.length_freq[word_len][letter] += 1\n",
    "            \n",
    "            # Transition probabilities: Bigrams\n",
    "            for i in range(len(word) - 1):\n",
    "                self.bigram_prob[word[i]][word[i+1]] += 1\n",
    "            \n",
    "            # Transition probabilities: Trigrams\n",
    "            for i in range(len(word) - 2):\n",
    "                self.trigram_prob[word[i]][word[i+1]][word[i+2]] += 1\n",
    "        \n",
    "        print(f\"✓ Trained on {len(words)} words\")\n",
    "        print(f\"  Emission models: {len(self.emission_prob)} word lengths\")\n",
    "        print(f\"  Bigrams: {sum(len(v) for v in self.bigram_prob.values())}\")\n",
    "        print(f\"  Trigrams: {sum(sum(len(vv) for vv in v.values()) for v in self.trigram_prob.values())}\")\n",
    "    \n",
    "    def get_emission_prob(self, masked_word, letter, available_letters):\n",
    "        \"\"\"Calculate emission probability P(letter | positions)\"\"\"\n",
    "        word_len = len(masked_word)\n",
    "        \n",
    "        if word_len not in self.emission_prob:\n",
    "            return 0.0\n",
    "        \n",
    "        prob = 0.0\n",
    "        count_positions = 0\n",
    "        \n",
    "        # Average probability across unknown positions\n",
    "        for pos, char in enumerate(masked_word):\n",
    "            if char == '_' and pos in self.emission_prob[word_len]:\n",
    "                pos_counter = self.emission_prob[word_len][pos]\n",
    "                total = sum(pos_counter.values())\n",
    "                if total > 0:\n",
    "                    # Laplace smoothing\n",
    "                    prob += (pos_counter[letter] + self.smoothing) / (total + self.smoothing * 26)\n",
    "                    count_positions += 1\n",
    "        \n",
    "        return prob / count_positions if count_positions > 0 else 0.0\n",
    "    \n",
    "    def get_transition_prob(self, masked_word, letter, available_letters):\n",
    "        \"\"\"Calculate transition probability using bigrams/trigrams\"\"\"\n",
    "        prob = 0.0\n",
    "        contexts = 0\n",
    "        \n",
    "        # Check bigram context\n",
    "        for i, char in enumerate(masked_word):\n",
    "            if char == '_':\n",
    "                # Left context\n",
    "                if i > 0 and masked_word[i-1] != '_':\n",
    "                    left = masked_word[i-1]\n",
    "                    total = sum(self.bigram_prob[left].values())\n",
    "                    if total > 0:\n",
    "                        prob += (self.bigram_prob[left][letter] + self.smoothing) / (total + self.smoothing * 26)\n",
    "                        contexts += 1\n",
    "                \n",
    "                # Right context\n",
    "                if i < len(masked_word) - 1 and masked_word[i+1] != '_':\n",
    "                    right = masked_word[i+1]\n",
    "                    # Find letters that come before 'right'\n",
    "                    for l in available_letters:\n",
    "                        total = sum(self.bigram_prob[l].values())\n",
    "                        if total > 0 and l == letter:\n",
    "                            prob += (self.bigram_prob[l][right] + self.smoothing) / (total + self.smoothing * 26)\n",
    "                            contexts += 1\n",
    "                            break\n",
    "        \n",
    "        # Check trigram context\n",
    "        for i in range(1, len(masked_word) - 1):\n",
    "            if masked_word[i] == '_':\n",
    "                left1 = masked_word[i-1] if i > 0 else None\n",
    "                right1 = masked_word[i+1] if i < len(masked_word) - 1 else None\n",
    "                \n",
    "                if left1 and left1 != '_' and right1 and right1 != '_':\n",
    "                    # Middle position in trigram\n",
    "                    if left1 in self.trigram_prob and letter in self.trigram_prob[left1]:\n",
    "                        total = sum(self.trigram_prob[left1][letter].values())\n",
    "                        if total > 0:\n",
    "                            prob += (self.trigram_prob[left1][letter][right1] + self.smoothing) / (total + self.smoothing * 26)\n",
    "                            contexts += 1\n",
    "        \n",
    "        return prob / contexts if contexts > 0 else 0.0\n",
    "    \n",
    "    def get_letter_probabilities(self, masked_word, guessed_letters):\n",
    "        \"\"\"Get probability distribution for next letter\"\"\"\n",
    "        available_letters = set('abcdefghijklmnopqrstuvwxyz') - guessed_letters\n",
    "        word_len = len(masked_word)\n",
    "        \n",
    "        if not available_letters:\n",
    "            return {}\n",
    "        \n",
    "        probabilities = {}\n",
    "        \n",
    "        for letter in available_letters:\n",
    "            # Emission probability (from HMM states)\n",
    "            emission = self.get_emission_prob(masked_word, letter, available_letters)\n",
    "            \n",
    "            # Transition probability (from N-grams)\n",
    "            transition = self.get_transition_prob(masked_word, letter, available_letters)\n",
    "            \n",
    "            # Length-specific frequency\n",
    "            length_prob = 0.0\n",
    "            if word_len in self.length_freq:\n",
    "                total = sum(self.length_freq[word_len].values())\n",
    "                if total > 0:\n",
    "                    length_prob = (self.length_freq[word_len][letter] + self.smoothing) / (total + self.smoothing * 26)\n",
    "            \n",
    "            # Global frequency\n",
    "            global_prob = 0.0\n",
    "            total_global = sum(self.unigram_freq.values())\n",
    "            if total_global > 0:\n",
    "                global_prob = (self.unigram_freq[letter] + self.smoothing) / (total_global + self.smoothing * 26)\n",
    "            \n",
    "            # Adaptive weighting based on revealed ratio\n",
    "            revealed_ratio = sum(1 for c in masked_word if c != '_') / len(masked_word)\n",
    "            \n",
    "            if revealed_ratio < 0.2:  # Early game\n",
    "                probabilities[letter] = 0.1 * emission + 0.1 * transition + 0.3 * length_prob + 0.5 * global_prob\n",
    "            elif revealed_ratio < 0.5:  # Mid game\n",
    "                probabilities[letter] = 0.25 * emission + 0.25 * transition + 0.3 * length_prob + 0.2 * global_prob\n",
    "            else:  # Late game\n",
    "                probabilities[letter] = 0.3 * emission + 0.4 * transition + 0.2 * length_prob + 0.1 * global_prob\n",
    "        \n",
    "        # Normalize\n",
    "        total = sum(probabilities.values())\n",
    "        if total > 0:\n",
    "            probabilities = {k: v/total for k, v in probabilities.items()}\n",
    "        \n",
    "        return probabilities\n",
    "\n",
    "print(\"✓ ImprovedHMM class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed6cff",
   "metadata": {},
   "source": [
    "## 3. Train the Improved HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9eed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train improved HMM\n",
    "improved_hmm = ImprovedHMM(smoothing=0.1)\n",
    "improved_hmm.train(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aebd70",
   "metadata": {},
   "source": [
    "## 4. Improved HMM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedHMMAgent:\n",
    "    \"\"\"Hangman agent using Improved HMM\"\"\"\n",
    "    \n",
    "    def __init__(self, hmm_model):\n",
    "        self.hmm = hmm_model\n",
    "        self.vowels = set('aeiou')\n",
    "        \n",
    "    def get_action(self, masked_word, guessed_letters, lives_remaining):\n",
    "        \"\"\"Select next letter to guess\"\"\"\n",
    "        available = set('abcdefghijklmnopqrstuvwxyz') - guessed_letters\n",
    "        \n",
    "        if not available:\n",
    "            return None\n",
    "        \n",
    "        # Get probabilities from HMM\n",
    "        probs = self.hmm.get_letter_probabilities(masked_word, guessed_letters)\n",
    "        \n",
    "        revealed_ratio = sum(1 for c in masked_word if c != '_') / len(masked_word)\n",
    "        \n",
    "        # Early game: prioritize vowels\n",
    "        if revealed_ratio < 0.15:\n",
    "            available_vowels = available & self.vowels\n",
    "            if available_vowels:\n",
    "                # Boost vowel probabilities\n",
    "                for vowel in available_vowels:\n",
    "                    if vowel in probs:\n",
    "                        probs[vowel] *= 2.0\n",
    "        \n",
    "        # Critical situation: be conservative\n",
    "        if lives_remaining <= 2 and probs:\n",
    "            # Filter very low probabilities\n",
    "            high_conf = {k: v for k, v in probs.items() if v > 0.05}\n",
    "            if high_conf:\n",
    "                return max(high_conf.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Normal selection\n",
    "        if probs:\n",
    "            return max(probs.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Fallback\n",
    "        default_order = 'etaoinshrdlcumwfgypbvkjxqz'\n",
    "        for letter in default_order:\n",
    "            if letter in available:\n",
    "                return letter\n",
    "        \n",
    "        return list(available)[0] if available else None\n",
    "\n",
    "print(\"✓ ImprovedHMMAgent class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1fe8f",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60922c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(word, agent, max_lives=6, verbose=False):\n",
    "    \"\"\"Play a single Hangman game\"\"\"\n",
    "    masked = '_' * len(word)\n",
    "    guessed = set()\n",
    "    lives = max_lives\n",
    "    wrong_guesses = 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nWord: {word}\")\n",
    "        print(f\"Start: {masked}\")\n",
    "    \n",
    "    while lives > 0 and '_' in masked:\n",
    "        letter = agent.get_action(masked, guessed, lives)\n",
    "        \n",
    "        if letter is None:\n",
    "            break\n",
    "        \n",
    "        guessed.add(letter)\n",
    "        \n",
    "        if letter in word:\n",
    "            masked = ''.join(word[i] if word[i] == letter or masked[i] != '_' else '_' \n",
    "                            for i in range(len(word)))\n",
    "            if verbose:\n",
    "                print(f\"✓ {letter}: {masked}\")\n",
    "        else:\n",
    "            lives -= 1\n",
    "            wrong_guesses += 1\n",
    "            if verbose:\n",
    "                print(f\"✗ {letter} (Lives: {lives})\")\n",
    "    \n",
    "    won = '_' not in masked\n",
    "    if verbose:\n",
    "        print(f\"Result: {'WON' if won else 'LOST'} (Wrong: {wrong_guesses})\")\n",
    "    \n",
    "    return {\n",
    "        'won': won,\n",
    "        'wrong_guesses': wrong_guesses,\n",
    "        'total_guesses': len(guessed)\n",
    "    }\n",
    "\n",
    "def evaluate_agent(agent, test_words, max_lives=6):\n",
    "    \"\"\"Evaluate agent on all test words\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for word in tqdm(test_words, desc=\"Evaluating\"):\n",
    "        result = play_game(word, agent, max_lives=max_lives, verbose=False)\n",
    "        results.append(result)\n",
    "    \n",
    "    wins = sum(1 for r in results if r['won'])\n",
    "    total_wrong = sum(r['wrong_guesses'] for r in results)\n",
    "    avg_wrong = total_wrong / len(results)\n",
    "    success_rate = wins / len(results)\n",
    "    \n",
    "    final_score = (success_rate * 2000) - (total_wrong * 5)\n",
    "    \n",
    "    return {\n",
    "        'num_games': len(results),\n",
    "        'wins': wins,\n",
    "        'success_rate': success_rate,\n",
    "        'total_wrong_guesses': total_wrong,\n",
    "        'avg_wrong_guesses': avg_wrong,\n",
    "        'final_score': final_score,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e06deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample words\n",
    "agent = ImprovedHMMAgent(improved_hmm)\n",
    "\n",
    "print(\"Testing on sample words:\")\n",
    "for word in test_words[:5]:\n",
    "    result = play_game(word, agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2da014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full evaluation\n",
    "print(\"\\nEvaluating Improved HMM on full test set...\")\n",
    "results = evaluate_agent(agent, test_words)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVED HMM EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Games: {results['num_games']}\")\n",
    "print(f\"Wins: {results['wins']} ({results['success_rate']:.2%})\")\n",
    "print(f\"Total Wrong Guesses: {results['total_wrong_guesses']}\")\n",
    "print(f\"Avg Wrong Guesses: {results['avg_wrong_guesses']:.3f}\")\n",
    "print(f\"\\nFINAL SCORE: {results['final_score']:.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Original HMM:   19.80% success, -55,324 score\")\n",
    "print(f\"RL + HMM:       19.90% success, -55,302 score\")\n",
    "print(f\"Improved HMM:   {results['success_rate']:.2%} success, {results['final_score']:.0f} score\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4783b",
   "metadata": {},
   "source": [
    "## 6. Save Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model data (convert defaultdicts to dicts)\n",
    "model_data = {\n",
    "    'emission_prob': improved_hmm.emission_prob,\n",
    "    'bigram_prob': {k: dict(v) for k, v in improved_hmm.bigram_prob.items()},\n",
    "    'trigram_prob': {k: {k2: dict(v2) for k2, v2 in v.items()} \n",
    "                     for k, v in improved_hmm.trigram_prob.items()},\n",
    "    'unigram_freq': dict(improved_hmm.unigram_freq),\n",
    "    'length_freq': improved_hmm.length_freq,\n",
    "    'smoothing': improved_hmm.smoothing\n",
    "}\n",
    "\n",
    "with open('improved_hmm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"✓ Model saved to 'improved_hmm_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb402f",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Improvements to HMM:\n",
    "\n",
    "1. **N-gram Transition Probabilities**\n",
    "   - Added bigram and trigram models\n",
    "   - Models letter sequence patterns\n",
    "   - Helps predict next letter based on context\n",
    "\n",
    "2. **Laplace Smoothing**\n",
    "   - Handles unseen patterns gracefully\n",
    "   - Prevents zero probabilities\n",
    "   - Improves generalization\n",
    "\n",
    "3. **Context-Aware Predictions**\n",
    "   - Uses revealed letters for better predictions\n",
    "   - Bigram context (left/right neighbors)\n",
    "   - Trigram context (surrounding letters)\n",
    "\n",
    "4. **Adaptive Weighting**\n",
    "   - Different strategies for early/mid/late game\n",
    "   - Balances emission and transition probabilities\n",
    "   - Adjusts based on revealed_ratio\n",
    "\n",
    "5. **Strategic Letter Selection**\n",
    "   - Vowel prioritization in early game\n",
    "   - Conservative selection when lives are low\n",
    "   - Smart fallback strategy\n",
    "\n",
    "### Expected Improvement:\n",
    "- Original HMM: ~20% success\n",
    "- **Improved HMM: 28-32% success** (estimated)\n",
    "- Still maintains HMM framework as required\n",
    "- Adds transition probabilities (key HMM component)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
