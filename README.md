# Intelligent Hangman Agent - ML Hackathon

**Course:** UE23CS352A - Machine Learning Lab  
**Project:** Intelligent Hangman Assistant  
**Author:** Beeresh CS141  
**Date:** November 2025

---

## ğŸ† Final Results - Best Solution

### Enhanced N-gram Agent Performance

| Metric | Value |
|--------|-------|
| **Success Rate** | **35.70%** (714/2000 wins) |
| **Final Score** | **-50,471** |
| **Total Wrong Guesses** | 10,237 |
| **Avg Wrong Guesses** | 5.119 per game |
| **Improvement over Baseline** | **+79.4%** success rate |
| **Score Improvement** | **+4,831 points** |

---

## ğŸ“Š All Approaches Comparison

| Agent | Success Rate | Final Score | Avg Wrong | Status |
|-------|--------------|-------------|-----------|---------|
| Original HMM | 19.80% | -55,324 | 5.572 | HMM Baseline |
| RL + HMM | 19.90% | -55,302 | 5.570 | Hybrid Approach |
| **Improved HMM** | **24.60%** | **-53,878** | **5.437** | âœ… **+24% over HMM** |
| **Enhanced N-gram** | **35.70%** | **-50,471** | **5.119** | âœ… **BEST OVERALL** |
| Optimized N-gram | 31.95% | -51,561 | 5.220 | Over-complicated |
| Fine-Tuned N-gram | 35.70% | -50,521 | 5.123 | Same as Enhanced |

---

## ğŸš€ Quick Start

### 1. Setup Environment
```powershell
cd "ML Hackathon"
python -m venv venv
.\venv\Scripts\activate
pip install numpy pandas matplotlib seaborn scikit-learn tqdm jupyter notebook
```

### 2. Run Best Solution
```powershell
jupyter notebook Enhanced_Strategy.ipynb
# Run all cells to train and evaluate
```

---

## ğŸ“ Project Structure

```
ML Hackathon/
â”œâ”€â”€ Data/Data/
â”‚   â”œâ”€â”€ corpus.txt                 # 49,954 training words
â”‚   â””â”€â”€ test.txt                   # 2,000 test words
â”œâ”€â”€ Enhanced_Strategy.ipynb        # ğŸ† BEST SOLUTION (35.7%)
â”œâ”€â”€ Improved_HMM.ipynb             # âœ… Enhanced HMM (24.6%)
â”œâ”€â”€ Dataset_Analysis.ipynb         # Data preprocessing
â”œâ”€â”€ HMM_Training.ipynb             # HMM baseline (19.8%)
â”œâ”€â”€ RL_Agent.ipynb                 # Q-Learning baseline (19.9%)
â”œâ”€â”€ Evaluation.ipynb               # Evaluation framework
â”œâ”€â”€ enhanced_agent.pkl             # Best N-gram model
â”œâ”€â”€ improved_hmm_model.pkl         # Improved HMM model
â”œâ”€â”€ improved_hmm_results.png       # Visualization
â”œâ”€â”€ IMPROVED_HMM_RESULTS.md        # Detailed HMM results
â””â”€â”€ README.md                      # This file
```

---

## ğŸ” Project Evolution & Key Learnings

### Phase 1: Baseline Approaches (19.8-19.9%)
- **RL + HMM:** 19.90% - Over-relied on Q-table
- **Pure HMM:** 19.80% - Needed exact word matches

### Phase 2: Critical Discovery
- Found **0% word overlap** between train/test
- Found **100% bigram coverage**
- **Insight:** Need character patterns, not word memorization!

### Phase 3: Improved HMM with Transitions (24.6%)
- Added **bigram** and **trigram** transition probabilities to HMM
- Enhanced emission probabilities with Laplace smoothing
- Adaptive weighting based on game state
- **Result:** +24.2% improvement over baseline HMM!

### Phase 4: Enhanced N-gram Solution (35.7%) âœ…
- **676 bigrams** + **8,148 trigrams**
- Adaptive weighting by game state
- **Result:** +79.4% improvement over baseline!

### Phase 5: Failed Optimizations
- Over-complicated â†’ worse performance
- **Lesson:** Simplicity wins!

---

## ğŸ§  How Enhanced Agent Works

### N-gram Components:
- **Unigram:** Global letter frequencies
- **Bigram (676):** Patterns like "th", "er", "ing"
- **Trigram (8,148):** Patterns like "tion", "ent"
- **Position-aware:** Letter frequencies by position
- **Length-specific:** Patterns for different word lengths

### Adaptive Strategy:
```
Early Game (< 20% revealed):  Prioritize vowels, global patterns
Mid Game (20-60%):            Balanced approach
Late Game (> 60%):            Heavy trigram/bigram context
Critical (â‰¤ 2 lives):         Most confident choice only
```

---

## ğŸ’¡ Why It Works

**Character patterns transfer despite 0% word overlap:**
- Training: "incredible", "kingdom"
- Test: "bringing" (unseen)
- Known patterns: "br", "ing", "gi" â†’ successful prediction!

---

## ğŸ“¦ Dependencies

```bash
pip install numpy pandas matplotlib seaborn scikit-learn tqdm jupyter notebook
```

---

## âœ… Deliverables

- âœ… `Enhanced_Strategy.ipynb` - Best solution
- âœ… `enhanced_agent.pkl` - Trained model
- âœ… `enhanced_results.txt` - Detailed results
- âœ… `enhanced_agent_results.png` - Visualizations
- âœ… All supporting notebooks and analysis

---

## ğŸ¯ Evaluation Formula

```
Final Score = (Success Rate Ã— 2000) - (Wrong Guesses Ã— 5) - (Repeated Guesses Ã— 2)
= (0.357 Ã— 2000) - (10,237 Ã— 5) - (0 Ã— 2)
= -50,471
```

---

## ğŸ“ Key Learnings

1. **0% overlap is correct** - Tests true generalization
2. **Character patterns > word memorization**
3. **Adaptive strategies > fixed rules**
4. **Simplicity > over-engineering**
5. **Multiple features provide robustness**

---

## ğŸ‘¥ Project Info

**Repository:** https://github.com/Beeresh-CS141/ml-hackathon  
**Course:** UE23CS352A - Machine Learning Lab  
**Status:** âœ… **COMPLETE**

---

*Last Updated: November 3, 2025*
